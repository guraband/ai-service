{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from eval import get_eval_data, pointwise_eval\n",
    "from utils import summarize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비용 기반 후보 모델 선정\n",
    "- claude-3-5-haiku-20241022\n",
    "- gpt-4o-mini\n",
    "- gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01: 맞다요즘 싸이월드 새로 생겼다매\n",
      "P02: 나 싸이월드 복구하고 싶다\n",
      "P01: 웅 키키귀여우뉴사진\n",
      "P02: 진짜 추억돋네\n",
      "P01: 짱많아 옛날 사진들\n",
      "P01: 맨날 퍼가요~ 이거 했자나\n",
      "P02: 맞아 싸이월드 미니미\n",
      "P01: 추억 돋아서 너무조아\n",
      "P02: 꾸미는거\n",
      "P01: 마자\n",
      "P02: 재밌었는데\n",
      "P01: 귀여워 도토리충전\n",
      "P02: 네이트온도 하고\n",
      "P02: 도토리도 환불해준대자나\n",
      "P01: 마자 키키개웃겨\n",
      "P01: 요즘 사회적으로 멀 자꾸하나바\n",
      "P02: 대박이야 진짜\n",
      "P02: 그니깐 키키\n",
      "P01: 아니 나오늘 엄마가 뭐 신청해달라그래서\n",
      "P02: 웅\n",
      "P01: 지원금 ? 신청함\n",
      "P01: 진짜 요즘 지원금 엄청 많이 받았어\n",
      "P02: 와 대박\n",
      "P01: 뭔지는 잘 모르는데 이것저것 지원해주는거 많아서 좋은듯\n",
      "P02: 다행이다\n",
      "P01: 국가제도가 진짜 괜차나\n",
      "P01: 학교에서도\n",
      "P02: 두분다\n",
      "P01: 맨날 장학금 해준다고\n",
      "P02: 일을 못하는\n",
      "P01: 이것저것 지원해주자나\n",
      "P02: 상황이셔서 더\n",
      "P01: 마자ㅠㅠ\n",
      "P02: 도움주시고\n",
      "P01: 나 그래서 진짜 그런거로\n",
      "P02: 다행이다그래도\n",
      "P01: 돈 마니받앗어\n",
      "P02: 와대박\n"
     ]
    }
   ],
   "source": [
    "eval_data = get_eval_data()\n",
    "\n",
    "for conv in eval_data[:1]:\n",
    "    print(conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BASELINE = f\"\"\"아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "싸이월드 복구와 추억의 미니미, 도토리 등을 회상하며 즐거워하는 대화 중에, 최근 국가의 다양한 지원금과 장학금 등 사회적 제도에 대해 긍정적으로 이야기를 나누고 있다. 특히 현재 상황에서 받은 지원금에 대해 감사함을 표현하며 대화를 이어가고 있다.\n",
      "====================================================================================================\n",
      "AI 어시스턴트의 답변은 대화의 주요 주제와 흐름을 잘 요약하고 있으며, 싸이월드와 관련된 추억과 국가 지원금에 대한 긍정적인 대화를 정확하게 반영하고 있습니다. 그러나 답변이 다소 일반적이고, 대화의 세부적인 내용이나 감정적인 뉘앙스를 충분히 담아내지 못한 점이 아쉽습니다.\n",
      "\n",
      "Rating: [[7]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=eval_data[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model=\"claude-3-5-haiku-20241022\"\n",
    ")\n",
    "\n",
    "eval_comment = pointwise_eval(eval_data[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(\"=\"*100)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 사용자는 새로 생긴 싸이월드에 대한 추억을 공유하며, 특히 미니미 꾸미기, 도토리 충전, 네이트온 등 과거 싸이월드 경험에 대한 향수를 느낀다. 대화는 자연스럽게 정부 지원금 및 장학금 이야기로 이어져, P01은 최근 여러 지원을 통해 금전적 도움을 많이 받았다고 언급한다. P02는 P01의 부모님 상황을 고려하며 국가 제도의 도움에 대해 긍정적으로 반응한다.\n",
      "\n",
      "====================================================================================================\n",
      "AI 어시스턴트의 답변은 대화의 주요 주제와 흐름을 잘 요약하고 있으며, 사용자가 나눈 대화의 핵심 포인트를 정확하게 짚어내고 있습니다. 싸이월드에 대한 추억과 정부 지원금에 대한 이야기를 모두 포함하여 대화의 전반적인 맥락을 잘 전달하고 있습니다. 그러나 추가적인 정보나 새로운 인사이트를 제공하지는 않았습니다.\n",
      "\n",
      "Rating: [[8]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=eval_data[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model=\"gemini-2.0-flash\"\n",
    ")\n",
    "\n",
    "eval_comment = pointwise_eval(eval_data[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(\"=\"*100)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자들은 최근 싸이월드의 복구 소식과 그로 인해 떠오르는 추억에 대해 이야기하고 있다. 또한, 지원금 신청과 관련된 긍정적인 경험을 공유하며 국가의 지원 제도에 대해 감사함을 표현하고 있다. 대화는 과거의 즐거운 기억과 현재의 지원 혜택에 대한 기쁨을 나누는 내용으로 진행된다.\n",
      "====================================================================================================\n",
      "AI 어시스턴트의 답변은 대화의 내용을 요약하는 데 중점을 두고 있으며, 대화의 주요 주제인 싸이월드 복구와 지원금 신청에 대한 사용자들의 감정을 잘 반영하고 있습니다. 그러나 사용자가 구체적인 질문을 한 것이 아니기 때문에, 답변이 직접적인 도움이 되지는 않습니다. 요약 자체는 정확하고 관련성이 있지만, 추가적인 정보나 조언을 제공하지 않아 다소 제한적입니다.\n",
      "\n",
      "Rating: [[6]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=eval_data[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "eval_comment = pointwise_eval(eval_data[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(\"=\"*100)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 사용자는 싸이월드를 통해 추억을 공유하고, 최근 지원금을 받아 도움을 받았다는 이야기를 나누며 국가제도에 대해 이야기하고 있다.\n",
      "====================================================================================================\n",
      "AI 어시스턴트의 응답은 대화의 요약을 제공하며, 대화의 주요 주제인 싸이월드와 지원금에 대한 내용을 잘 반영하고 있습니다. 그러나 응답이 단순한 요약에 그치고 있어, 추가적인 정보나 대화의 흐름을 이어가는 데에는 부족함이 있습니다. \n",
      "\n",
      "Rating: [[6]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=eval_data[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model=\"gpt-3.5-turbo-0125\"\n",
    ")\n",
    "\n",
    "eval_comment = pointwise_eval(eval_data[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(\"=\"*100)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(135, 140), match='[[4]]'>\n",
      "[[4]]\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "s = f\"\"\"AI 어시스턴트의 답변은 대화의 주요 주제와 흐름을 잘 요약하고 있으며, 싸이월드와 관련된 추억, 그리고 국가 지원금에 대한 긍정적인 대화를 정확하게 반영하고 있습니다. 그러나 답변이 단순 요약에 그치고 있어, 추가적인 정보나 새로운 인사이트를 제공하지 못한 점이 아쉽습니다.\n",
    "\n",
    "Rating: [[7]]\"\"\"\n",
    "\n",
    "pattern = r'\\[\\[(\\d+)\\]\\]'\n",
    "\n",
    "match = re.search(pattern, eval_comment)\n",
    "print(match)\n",
    "print(match.group(0))\n",
    "print(match.group(1))\n",
    "score = int(match.group(1))\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b80c3117d064c3b8a0a43b8c753274a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6b5666c5de43718e24e2ab5e289ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ade732598ef469e85e83733e84a7d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b898a25952084fa3ac4ef2cea8448065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991cfe3e43f24c9a94538fca6a25bfe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claude-3-5-haiku-20241022': [6, 6, 4, 7, 7], 'gemini-2.0-flash': [7, 6, 4, 7, 8], 'gemini-1.5-flash': [6, 5, 7, 8, 7], 'gpt-4o-mini': [6, 7, 6, 8, 6], 'gpt-3.5-turbo-0125': [6, 3, 4, 8, 4]}\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    \"claude-3-5-haiku-20241022\",\n",
    "    \"gemini-2.0-flash\",\n",
    "    \"gemini-1.5-flash\",\n",
    "    \"gpt-4o-mini\",\n",
    "    \"gpt-3.5-turbo-0125\"\n",
    "]\n",
    "\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[(\\d+)\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    for i in tqdm(range(len(eval_data[:5]))):\n",
    "        summary = summarize(\n",
    "            conversation=eval_data[i],\n",
    "            prompt=PROMPT_BASELINE,\n",
    "            model=model\n",
    "        )\n",
    "        eval_comment = pointwise_eval(eval_data[i], summary)\n",
    "        # print(eval_comment)\n",
    "        match = re.search(pattern, eval_comment)\n",
    "        # print(match)\n",
    "        score = int(match.group(1)) if match else 0\n",
    "        scores[model].append(score)\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-5-haiku-20241022 7 4 6.0 0.82\n",
      "gemini-2.0-flash 8 4 6.4 0.79\n",
      "gemini-1.5-flash 8 5 6.6 0.85\n",
      "gpt-4o-mini 8 6 6.6 0.88\n",
      "gpt-3.5-turbo-0125 8 3 5.0 0.64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for model in scores:\n",
    "    print(model, max(scores[model]), min(scores[model]), sum(scores[model]) / len(scores[model]),\n",
    "          round(1 - np.std(scores[model]) / np.mean(scores[model]), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
